#ImplicitSampler.py
#create a class that samples our sparse data on implicit feedback
#to create sample of negative labels 
#for computationally tractable model fitting

#idea: partition data into groups (sample_features) and resample these;
#also has some helper functions for generating probabilities for both sampling tokens and features (in the case of twostep)


import keras
assert tuple([int(i) for i in keras.__version__.split('.')]) >= (2,0,8), "Need Keras version 2.0.8"
from keras.callbacks import Callback
import math
import time
import random
import threading
from functools import wraps
import pandas as pd
import numpy as np
import gc
import cProfile
from keras.engine.training import GeneratorEnqueuer
from keras.utils.generic_utils import Progbar
import keras.preprocessing.sequence as sequence


def monkeypatch_method(cls):
    """
    Creates a decoration for monkey-patching a class
    Recipe from: https://mail.python.org/pipermail/python-dev/2008-January/076194.html
    Args:
        cls:

    Returns:

    """
    @wraps(cls)
    def decorator(func):
        setattr(cls, func.__name__, func)
        return func
    return decorator

@monkeypatch_method(pd.DataFrame)
def to_keras_flex_format(self,feature_cols=None,text_dict=None,cutoff=None):
    '''
    Converts a DF to a generator ready for compatibility with Keras Fmachine Model
    Arguments
    :param feature_cols is an (ordered) list of columns (so a list of lists) corresponding to each feature in the keras model 
    in "feature". can either be names of columns in DFs or the indices 
        (e.g. either ["feature1"], [1], or ['feature1','feature2'] as an ex. entry in the list)
    :param text_dict: a dictionary converting words/characters to integers when dealing with text
    :param cutoff: a cutoff (max # of tokens) to implement for the sequence created that is fed to keras
    '''
    #the default is deprecated; no longer support categoricals (must be converted to codes beforehand
    if feature_cols is None:
        return [self[f].cat.codes if self[f].dtype.name == "category" else self[f] for f in self.columns]
    else:
        feature_list=[]
        for d in feature_cols:
            if self[d].dtypes.values.tolist()==[np.dtype('O')]:
                #we assume all object columns are strings / text features
                seq=sequence.pad_sequences(self[d],
                                           maxlen=cutoff,value=0,padding='post',truncating='post',dtype=np.int16)
                #print seq
                feature_list.append(seq)            
            else:
                numeric_feat_cols = [self[f] for f in d]   
                feature_list.append(np.array(pd.concat(numeric_feat_cols,axis=1)))
        return feature_list
   



def process_features(df):
    '''
    clean features so that they are ready for input into our generator for the keras model.
    returns: a dictionary mapping integers to categories where relevant.
    '''
    feature_label_dict = {}
    for c in df.columns:
        if df[c].dtype.name=='category':
            feature_label_dict[c]=dict([(category, code) for code, category in enumerate(df[c].cat.categories)])
            df[c] = df[c].cat.codes
        elif df[c].dtype.name=='object':
            df[c] = df[c].str.lower().str.decode('utf-8','ignore').str.encode("utf-8")
    return feature_label_dict

def gen_step1_probs(fm,feature_names,alpha):
    '''
    given a keras model and feature names, extract parameter counts and return the step 1 probabilities 
    for the twostep sampler
    params:
        fm: a keras model generated by DeepFM.build_model()
        feature_names: the NAMES of the features in the keras model. this is stored in the self.feature_names in a DeepFM object. if sampling_features != model_features (i.e. if some model_features are sampled together, such as, say, state and city) then you must specify a list of length = #sampling_features, where each element is itself a list of the model feature names to include for each sampling feature (in order).
        alpha: flattening parameter
    '''
    init_probs =  np.zeros(shape=len(feature_names))
    if all(type(i)==list for i in feature_names):
        for i,sample_feats in enumerate(feature_names):
            for model_layers in sample_feats:
                for l in fm.layers:
                    if l.name=='embedding_{}'.format(model_layers) or l.name=='factor_{}'.format(model_layers):
                        init_probs[i] += l.count_params()
                        break
    else:
        for i,model_layers in enumerate(feature_names):
            for l in fm.layers:
                if l.name=='embedding_{}'.format(model_layers) or l.name=='factor_{}'.format(model_layers):
                    init_probs[i] += l.count_params()
                    break
    print "--Original Probs--" 
    print init_probs/np.sum(init_probs)
    init_probs = np.power(init_probs,alpha)
    init_probs = init_probs/np.sum(init_probs)
    print "--New Probs with alpha={}--".format(alpha)
    print init_probs  
    return init_probs


##################
#from https://github.com/fchollet/keras/issues/1638
#threadsafe generator that is compatible with multiple workers 
#no longer really used
class threadsafe_iter:
    """Takes an iterator/generator and makes it thread-safe by
    serializing call to the `next` method of given iterator/generator.
    """
    def __init__(self, it):
        self.it = it
        self.lock = threading.Lock()

    def __iter__(self):
        return self

    def next(self):
        with self.lock:
            return self.it.next()


def threadsafe_generator(f):
    """A decorator that takes a generator function and makes it thread-safe.
    """
    def g(*a, **kw):
        return threadsafe_iter(f(*a, **kw))
    return g
################

   
class SamplingStrategy(Callback):
    '''
    Class for generating probabilities for items in the data for sampling neg. labels.
    '''
    def __init__(self,features,items,strategy='uniform',alpha=None, bias=None):
        '''
        Class Initializer.
        Arguments:
            :param strategy: how we sample the new negative labels
                options are "popular", and "uniform", or None 
            :param alpha: how to flatten the unigram distribution we sample from
                0.0 corresponds to uniform, 1.0 corresponds to complete popular sampling.
            :param features: which features are being sampled?
                expects a list of features, which can be multidimensional 
                (e.g. you can pass 'household_id', or ['city,'state'] as a single element of the list of all features to sample
            :param items: possible values of sampled feature; again a list of combinations
                that can be multidimensional depending on the corresponding feature. should be a list of lists of tuples,
                but if single-dimensional could also be a list of lists of objects as long as they are hashable
            sample_bias: constant term added to count of labels in data for sampling from unigram
        '''
        self.df = None
        self.strategy_name = strategy
        if alpha is not None:
            self.alpha=alpha
        elif str.lower(self.strategy_name)=="uniform":
            self.alpha=0.
        elif str.lower(self.strategy_name)=="popular":
            self.alpha=1.
        if bias is None:
            self.bias=10
        else:
            self.bias=bias            
        self.features=features
        self.items= items

        assert isinstance(self.alpha, float), "Must provide sampling strategy or alpha term that is a float"  
        assert isinstance(self.features, list), "Must provide features as a list (even if its just one)"  

        Callback.__init__(self)
        
    def get_probabilities(self,df):
        '''
        given item set  and feature set, calculate probabilities for sampling for all features we sample
        '''
        self.df=df
        distros=[] #the list of probability vectors for each feature
        for f,i in zip(self.features,self.items):
            print "generating probs for " + str(f)
            if self.alpha==0:
                distros.append(np.array([1./len(i) for j in range(len(i))]))
            else:
                #standardize the items to IDs
                items_str= [hash(x) for x in i]
                temp_df =pd.Series([hash(tuple(x)) for x in self.df[f].values.tolist()])
                count_df =pd.DataFrame({"item": items_str ,'bias':self.bias}).set_index("item")
                count_df['count'] = temp_df.value_counts() + self.bias
                
                count_df.loc[count_df['count'].isnull(),'count'] = self.bias
                count_df['raw_prob'] = count_df['count']/count_df['count'].sum()
                count_df['distorted'] = count_df['raw_prob']**self.alpha
                count_df['dist'] = count_df['distorted']/count_df['distorted'].sum()
                distros.append(np.array(count_df['dist']))
        if len(self.features)==1:
            return distros[0]
        else:
            return distros    
    def get_probability(self,itemset,values):
        '''
        will get one individual set of empirical resampling probabilitites for neg labels
        less memory intensive than the previous methodology, which generates features for all at once,
        but slower
        '''
        if self.alpha==0:
            return np.array([1./len(i) for j in range(len(i))])
        else:
            count_df =pd.DataFrame({"index":range(len(itemset)) , "item": itemset }).set_index('item')
            vals = pd.DataFrame(values).groupby(0).size() 
            for i,item in enumerate(itemset):
                count_df.loc[i,'count']  = vals[item] + self.bias
            print count_df
            #count_df['count'] = pd.DataFrame(values).groupby(0).size() + self.bias
            count_df.loc[count_df['count'].isnull(),'count'] = self.bias
            #print pd.Series(temp_
            count_df['raw_prob'] = count_df['count']/count_df['count'].sum()
            count_df['distorted'] = count_df['raw_prob']**self.alpha
            count_df['dist'] = count_df['distorted']/count_df['distorted'].sum()
            print count_df
            return np.array(count_df['dist'])

############################
#Class: Implicit Sampler
#does the actual sampling based on probabilities generated by our sampling strategy
# using generators
class ImplicitSampler():
    '''
    This class does the sampling of the neg labels
    '''
    def __init__(self, df, negative_samples=1, 
                 sampling_features=None,model_features=None,
                 sampling_items=None, sampling_probs=None,
                 batch_size=None,
                 sampling_strategy=None, sampling_alpha=None,sampling_bias=None,
                 oversampler='twostep',init_probs = None,
                 keep_noise_probs=False,
                 text_dict=None,text_cutoff=None,
                 cache_epoch=False, sample_once=False,prob_dict=None):
        '''
        Class Initializer:
        Arguments:
            -df: the dataset of pos labels that we sample from
            -negative_samples: #of neg samples per pos sample
            -batch_size: size of each batch
            -sampling_features: a list of lists of the name(s) of the features, organized by how we are sampling them
                -use a list of columns in a DF (either numerical or string indices) 
                 to refer to columns sampled "jointly" i.e. features=['household',['city','state']]
                 if we wanted to oversample the schoolID and CS_offered vars together  
            -model_features: a list of lists of the name(s) of the features, organized by how we are inputting them
                into the keras model.
                -use a list of columns in a DF (either numerical or string indices) 
                 to refer to columns sampled "jointly" as a single feature 
                 (i.e. features=['household',['city','state']])
                 if we wanted to input the schoolID and CS_offered vars together)              
            -sampling_items: possible labels for each sample_feature we feed into the sampler. should be a list of lists of tuples
            sampling_probs: probabilities we associate with the sampling_items when we sample them.
                if not provided, generated on-the-fly by SamplingStrategy object used for sampling. should be a list of numpy arrays
            -sampling_strategy: how to gen probs of each label (of class SamplingStrategy)
            -sampling_alpha: an optional numeric paramater that controls how much to flatten the unigram sampling
                strategy. Used only if a SamplingStrategy Object is made on the fly
            -sampling_bias: how much to add to the count of each category. Used only if a SamplingStrategy Object is made on the fly
            -oversampler: how to oversample negative labels. only relevant for multi-feature samplers.  options are "twostep" and "all"
            -init_probs: probabilities to choose which feature to resample in step 1 of twostep multifeature sampler. only matters if we choose 2-step oversampler.
            -keep_noise_probs: whether to return the noise probabilities as a final argument to keras (in case you are doing NCE)
            -prob_dict: a dictionary of items to their probabilities; useful to pass in advance in case make multiple samplers to save memory, or do not want to recompute everytime you create this object. it should be a dictionary of dictionaries, where each sub-dict maps items to their probabilities, and the super-dict maps each sampling feature to its relevant item. Otherwise, the program will create one internally
            -cache_epoch: whether to store iterations of the neg lab df?
            -sample_once: whether to resample df only once
            -text_dict: a dictionary converting a string to a sequence of integers 
                (only relevant if we have text model features)
            -text_cutoff: the maximum length of a sequence 
                (only relevant if we have text model features)
        '''
        # Generator:
        self.df = df 
        if sampling_features is None:
            print "using all columns as sampling features since sampling_features arg was not passed"
            self.sampling_features = [[f] for f in self.df.columns]
        else:
            assert all([type(i)==list for i in sampling_features]), \
                "sampling_features must be a list of lists"
            for i in sampling_features:
                for j in i:
                    assert j in self.df.columns or \
                    (type(j)==int and j < len(self.df.columns) and j >=0), \
                    "all features should be column names or integers representing column locations"
            self.sampling_features = sampling_features
        if model_features is None:
            print "using all columns as model features since model_features arg was not passed"
            self.model_features =  [f for f in self.df.columns]
        else:
            self.model_features = model_features 
            assert all([type(i)==list for i in model_features]), \
                "model_features must be a list of lists"
            for i in model_features:
                for j in i:
                    assert j in self.df.columns or \
                    (type(j)==int and j < len(self.df.columns) and j >=0), \
                    "all sampling features should be column names or integers representing column locations in df"
        
         #if no items list given, just look at the set of our given labels
        if sampling_items is None:
            print "no sampling_items passed; generating unique item sets from df passed"
            sampling_items = []
            print self.sampling_features
            for f in self.sampling_features:
                sampling_items.append([tuple(i) for i in self.df[f].drop_duplicates().values.tolist()])
        assert len(sampling_items) == len(sampling_features), \
        "sampling items should be a list of length = length of  sampling_features"
        assert all(type(i)==list for i in sampling_items), \
        "sampling_items should be a list of lists of tuples (where each list of tuples are unique individual feature values)"
        self.items = sampling_items

        self.negative_samples = negative_samples
        
        if batch_size is None:
            print "setting batch_size to entire DF since no arg passed"
            self.batch_size = len(self.df)
        else:
            self.batch_size = batch_size
        self.cache_epoch = cache_epoch
        #self.positive_pairs = set(ImplicitSampler._get_tuples(self.df))
        self.epoch_cache_df = None
        self.sample_once = sample_once
        if self.sample_once and (not self.cache_epoch):
            raise RuntimeError("If sample_once is true, then cache_df should be true too")
     
        if sampling_strategy is None:
            self.sampling_strategy = SamplingStrategy(features=self.sampling_features,items=self.items,strategy='uniform',
                                                     alpha=sampling_alpha,bias=sampling_bias)
            self.sampling_alpha= self.sampling_strategy.alpha
            self.sampling_bias=self.sampling_strategy.bias 
        else:
            self.sampling_strategy = sampling_strategy
            self.sampling_alpha = sampling_strategy.alpha
        if sampling_probs is None:
            self.probabilities = self.sampling_strategy.get_probabilities(self.df)
        else:
            self.probabilities = sampling_probs
        if oversampler=='all':
            self.oversampler = self.extend_batch_oversample_all
        elif oversampler=='twostep':
            self.oversampler = self.extend_batch_oversample_twostep
        else:
            raise RuntimeError("oversampler of negative labels must be either 'twostep' or 'all' ")  
        self.keep_noise_probs= keep_noise_probs
        if init_probs is None:
            self.init_probs = np.ones(len(sampling_features))/len(sampling_features)
        else:
            assert type(init_probs)==np.ndarray and init_probs.shape==(len(sampling_features),), \
            "init_probs should be a 1D numpy array with length equal to number of sampling_features"
            self.init_probs = init_probs  
        if self.keep_noise_probs and prob_dict is None:
            print "calculating prob lookup dict for expedited sampling of negative labels..."
            self.prob_dict = {}
            for f,i,p in zip(self.sampling_features,self.items,self.probabilities):
                self.prob_dict[tuple(f)] = dict( zip([tuple(j) for j in list(i)],p) )
        else:
            self.prob_dict = prob_dict
        self.text_dict = text_dict         
        self.text_cutoff = text_cutoff         
        

    @staticmethod
    def chunker(df, size):
        '''
        splits df into minibatches of size "size".
        '''
        return (df.iloc[pos:pos + size] for pos in xrange(0, len(df), size))

    def get_epoch_size(self):
        '''
        return size of total dataset (pos+neg)
        '''
        return len(self.df) * (self.negative_samples + 1)
    
    def keras_generator(self):
        '''
        return generator of data for use in keras one-time during training
        '''
        xs, ys, ws = [], [], []
        while True:
            #if we have already sampled it and cached it, load it up
            if self.cache_epoch and self.sample_once and self.epoch_cache_df is not None:
                self.epoch_cache_df = self.epoch_cache_df.sample(frac=1)  # shuffle
                for batch in ImplicitSampler.chunker(self.epoch_cache_df, self.batch_size):
                    keras_covars = batch.to_keras_flex_format(feature_cols = self.model_features,
                                                 text_dict=self.text_dict,cutoff=self.text_cutoff)
                    if self.keep_noise_probs: 
                        keras_covars.append(batch['__noise_probs__'])
                    yield keras_covars,batch["_y_"], batch["_w_"]
            
            else:
                xs, ys, ws = [], [], []
                for x, y, w in self.sample_fast():
                    if self.cache_epoch:  # build cache
                        xs.append(x)
                        ys += y
                        ws += w.tolist()
                    if x is None or y is None or w is None:
                        print "for some reason, it returned none?"
                        print x,y,w
                    keras_covars = x.to_keras_flex_format(feature_cols = self.model_features,
                                                 text_dict=self.text_dict,cutoff=self.text_cutoff)
                    if self.keep_noise_probs: 
                        keras_covars.append(np.array(x['__noise_probs__']*self.negative_samples))
                    yield keras_covars, y, w
            #print "rerunning epoch..."
            if self.cache_epoch:
                self.epoch_cache_df = pd.concat(xs)
                self.epoch_cache_df["_y_"] = ys
                self.epoch_cache_df["_w_"] = ws
                
    def get_output(self, sampled_batch, explicit_len):
        '''
        generates the weights and target outcomes
        in the pos label dataset. currently we just give every obs weight 1.
        '''
        # Create target variables and weights:
        implicit_len = explicit_len * self.negative_samples
        y_explicit = [1.0] * explicit_len
        w_explicit = [1.0] * explicit_len
        y_implicit = [0.0] * implicit_len
        w_implicit = [1.] * implicit_len
        return y_explicit, y_implicit, w_explicit, w_implicit

    def extend_batch_oversample_all(self, batch):
        '''
        oversample the positive data to generate negative target data by resampling 
        every single one of the possible sampling_features.
        '''
        # Create implicit observations:
        sampled_batch = pd.concat([batch] * self.negative_samples, ignore_index=True)

        # Sample new labels with probabilities given by sampling_strategy:
        for itemset,featureset,prob in zip(self.items,self.sampling_features,self.probabilities):
            implicit_label_index = np.random.choice(len(itemset),
                                           len(sampled_batch),
                                           p=prob,
                                           replace=True)
            implicit_labels = [itemset[i] for i in implicit_label_index]
            # Update implicit observations with sampled labels:
            #have to handle single column samples differently
            if len(sampled_batch[featureset].shape)==1:
                sampled_batch[featureset] = implicit_labels
            else:
                for n,col in enumerate(featureset):
                    sampled_batch[col] = [l[n] for l in implicit_labels]
                
        #get weights/labels
        y_explicit, y_implicit, w_explicit, w_implicit = self.get_output(sampled_batch, len(batch))
        #combine pos + neg target data 
        ys = y_explicit + y_implicit
        ws = np.array(w_explicit + w_implicit)
        aug_batch = pd.concat([batch, sampled_batch], ignore_index=True)
        #generate probabilities if we use NCE
        if self.keep_noise_probs:
            aug_batch['__noise_probs__'] = 1.
            for itemset,featureset,prob in zip(self.items,self.sampling_features,self.probabilities):
                feature_probs = np.array([ self.prob_dict[tuple(featureset)][tuple(f)] for f in aug_batch[featureset].values.tolist() ])
                aug_batch['__noise_probs__'] = aug_batch['__noise_probs__'] * feature_probs
                
        return aug_batch, ys, ws


    
    def extend_batch_oversample_twostep(self, batch):
        '''
        oversample the positive data to generate negative target data.
        randomly chooses a feature according to self.init_probs, then changes it according to item-specific probs given
        '''
        # Create implicit observations:
        changed_feature = np.random.choice(len(self.sampling_features),size=len(batch),p=self.init_probs)
        sampled_batch = pd.concat([batch] * self.negative_samples, ignore_index=True)   
        neg_changed_feature = np.array([changed_feature]*self.negative_samples).flatten()
        # Sample new labels with probabilities given by sampling_strategy:
        for itemset,featureset,prob in zip(self.items,self.sampling_features,self.probabilities):
            feature_index = self.sampling_features.index(featureset)
            this_feature = neg_changed_feature==feature_index
            implicit_label_index = np.random.choice(len(itemset),
                                           np.sum(this_feature),
                                           p=prob,
                                           replace=True)
            #print implicit_label_index
            implicit_labels = [itemset[i] for i in implicit_label_index]
            #print implicit_labels
            if len(sampled_batch[featureset].shape)==1:
                sampled_batch.loc[this_feature,featureset[0]] = implicit_labels
            else:
                for n,col in enumerate(featureset):
                    sampled_batch.loc[this_feature,col] = [l[n] for l in implicit_labels]
             
        #print sampled_batch
        #get weights/labels
        y_explicit, y_implicit, w_explicit, w_implicit = self.get_output(sampled_batch, len(batch))
        #combine pos + neg target data 
        ys = y_explicit + y_implicit
        ws = np.array(w_explicit + w_implicit)
        aug_batch = pd.concat([batch, sampled_batch], ignore_index=True)
        changed_feature = np.concatenate([changed_feature,neg_changed_feature])
        
        if self.keep_noise_probs:
            noise_probs = np.ones(len(aug_batch))
            for itemset,featureset,prob in zip(self.items,self.sampling_features,self.probabilities):
                feature_index = self.sampling_features.index(featureset)
                this_feature = changed_feature==feature_index
                #print np.sum(this_feature),this_feature.shape
                feature_probs = np.array([ self.prob_dict[tuple(featureset)][tuple(f)] \
                                          for f in \
                                          aug_batch.loc[this_feature, \
                                          featureset].values.tolist()])
                noise_probs[this_feature] = noise_probs[this_feature] * feature_probs # * self.init_probs[feature_index] #should not multiply by first step probs since we condition on sampled feature for NCE loss
            aug_batch['__noise_probs__']= noise_probs
        return aug_batch, ys, ws

   

    def sample_fast(self, only_fold=None):
        '''
        samples new neg label dataset given the probs of each label.
            only_fold: only sample a given fold ID
        '''
        shuffled_df = self.df.sample(frac=1)
        for batch in ImplicitSampler.chunker(shuffled_df, self.batch_size):
            #aug_batch, ys, ws = self.extend_batch_oversample_twostep(batch, self.probabilities)
            aug_batch, ys, ws = self.oversampler(batch)
            yield aug_batch, ys, ws
    

